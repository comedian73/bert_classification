# bert_classification

BERT-подобная модель ИИ для классификации текстов.

### Задача

Дообучить BERT-подобную модель произвольным датасетом для классификации  текстов. Не менее 5 класслв.

### Что использую

* pandas - для работы с датасетом
* sklearn, imblearn - для обработки данных
* transformers - для загрузки токенизаторов и предобученой модели
* tensorflow - для корректной работы модели и обработки входных данных
* datasets - для загрузки датасета с Hugging Face
* matplotlib, seaborn - для визуализации
* ai-forever/headline-classification - датасет для обучения
* ai-forever/ruRoberta-large - предобученая модель

В результате работы получилась BERT-подобная дообученая модель, которая классифицирует текст по 6 классам (Спорт, Политика, Проишествия, Культура, Экономика, Наука).

Для просмотра кода работы по подготовки, обработки, визуализации данных и обучения модели с дольнейшим выводом примеров работы необходимо перейти в [Google Colab](https://colab.research.google.com/drive/1SyoWs4dL4X74j-anbR079FupyAA0qjyt?usp=sharing)
